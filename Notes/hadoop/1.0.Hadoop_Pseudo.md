# Hadoop Pseudo-Distribution

## Setup passphraseless ssh
Now check that you can ssh to the localhost without a passphrase:

>ssh localhost

If you cannot ssh to localhost without a passphrase, execute the following commands:
> 
    ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
    chmod 0600 ~/.ssh/authorized_keys 


## Unpack hadoop

    tar xf hadoop-2.7.7.tar.gz -C /opt/
    cd /opt
    mv hadoop-2.7.7/ hadoop

## Setup environment variables

>vi + /etc/profile
>
    export HADOOP_HOME=/opt/hadoop
    PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
> . /etc/profile
> 

## Define java home in Hadoop configuration files
* $HADOOP_HOME/etc/hadoop/hadoop-env.sh

* $HADOOP_HOME/etc/hadoop/mapred-env.sh

* $HADOOP_HOME/etc/hadoop/yarn-env.sh

>```export JAVA_HOME=/usr/java/jdk1.7.0_80```

## Configure Hadoop
* $HADOOP_HOME/etc/hadoop/core-site.xml

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://node01:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/var/hadoop/pseudo</value>
    </property>
</configuration>
```
* $HADOOP_HOME/etc/hadoop/hdfs-site.xml
```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node01:50090</value>
    </property>
</configuration>

```

* $HADOOP_HOME/etc/hadoop/slaves
```
node01
```

## Format hdfs
    hdfs namenode -format
>Verify by: 
>
    cd /var/hadoop/pseudo/dfs/name/current
    cat V*

## Start hdfs
    start-dfs.sh
> Verify by: jps
>
    Expected 4 processes:
    1901 Jps
    1618 DataNode
    1529 NameNode
    1792 SecondaryNameNode

## Web Console
<http://node01:50070>

## Hadoop file system operations
> Check Options
> 
>     hdfs dfs

> Examples
> 
>     hdfs dfs -mkdir -p /user/root
>     hdfs dfs -ls /

> Upload files
> 
>     hdfs dfs -put ~/software/hadoop-2.7.7.tar.gz /user/root

> File split into blocks and saved in 
> 
>     /var/hadoop/pseudo/dfs/data/current/BP-2100751933-192.168.9.31-1569778461969/current/finalized/subdir0/subdir0

> Can also check in web console -> Utilities -> Browse the file system

## Stop hdfs

    stop-dfs.sh